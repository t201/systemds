#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------
# Generate the logical pipelines for data cleaning

source("scripts/pipelines/scripts/utils.dml") as utils;

# read the inputs
F = read($dirtyData, data_type="frame", format="csv", header=TRUE, 
  naStrings= ["NA", "null","  ","NaN", "nan", "", "?", "99999"]);

metaInfo = read($metaData, data_type="frame", format="csv", header=FALSE);
primitives = read($primitives, data_type = "frame", format="csv", header= TRUE)
param = read($parameters, data_type = "frame", format="csv", header= TRUE)
logical = frame(["MVI", "DUMMY"], rows=1, cols=2)
sample = $sampleSize
topK = $topk
resources = $rv
crossValidations = $cv
weightedAccuracy = $weighted # accuracy flag
targetApplicaton = $target # accuracy flag
output = $output

if(nrow(metaInfo) < 2)
  stop("incomplete meta info")

getSchema = metaInfo[1, 2:ncol(metaInfo)]
getMask = as.matrix(metaInfo[2, 2:ncol(metaInfo)])
getFdMask = as.matrix(metaInfo[3, 2:ncol(metaInfo)]) # columns of interest for FD computation
  
# 1. dropInvalid function will remove the values which are not the part 
# of the column data type and convert the data to lowercase

X = utils::stringProcessing(F, getMask, getSchema)

# 2. encode the categorical data
if(sum(getMask) > 0)
{
  # always recode the label
  index = vectorToCsv(getMask)
  jspecR = "{ids:true, recode:["+index+"]}"
  [eX, X_meta] = transformencode(target=X, spec=jspecR);
  # change the schema to reflect the encoded values
  getSchema = map(getSchema, "x->x.replace(\"STRING\", \"INT64\")")
  getSchema = map(getSchema, "x->x.replace(\"BOOLEAN\", \"INT64\")")

} 
# if no categorical value exist then just cast the frame into matrix
else
  eX = as.matrix(X)
  
# 3. extract the class label  
eY = eX[, ncol(eX)]
eX = eX[, 1:ncol(eX) - 1]

getMask = getMask[, 1:ncol(getMask) - 1] # strip the mask of class label
getFdMask = getFdMask[, 1:ncol(getFdMask) - 1] # strip the mask of class label
getSchema = getSchema[, 1:ncol(getSchema) - 1] # strip the mask of class label


# 4. perform the sampling
[eX, eY] = utils::doSample(eX, eY, sample)

# 5. find the best hyper parameters for classification algorithm
# for now only find the best values for intercept and maximum outer iteration
opt = matrix("0 0 100", rows=1, cols=3)


# 6. get the cross validated accuracy on dirty dataset (only on training set)
d_accuracy = 0
d_accuracy = utils::classifyDirty(eX, eY, opt, getMask, weightedAccuracy, crossValidations)

if(sum(getFdMask) > 0)
{
  FD = discoverFD(X=replace(target=eX, pattern=NaN, replacement=1), Mask=getFdMask, threshold=0.8)
  FD = (diag(matrix(1, rows=nrow(FD), cols=1)) ==0) * FD 
  FD = FD > 0
}
FD = as.matrix(0)

metaList = list(mask=getMask, schema=getSchema, fd=FD)
targetClassification = list(target=targetApplicaton, cv=crossValidations, wAccuracy=weightedAccuracy, 
  dirAcc = d_accuracy, mlHp = opt, cleanData = as.matrix(0))

# # initialize output variables
# 7. call the optimizer
pip = as.frame("NULL"); hp = matrix(0,0,0); acc = matrix(0,0,0); features = as.frame("NULL")
[pip, hp, acc, features] = bandit(X_train=eX, Y_train=eY,  metaList=metaList, targetList=targetClassification, lp=logical,
  primitives=primitives, param=param, k=topK, R=resources, verbose=TRUE);


if(as.scalar((is.na(acc[1,1]))) == 1 | as.scalar(acc[1,1]) < d_accuracy)
  stop("warning: no best pipeline found")
  
print("best pipelines")
print(toString(pip))

print("best hyperparam")
print(toString(hp))

print("best accuracy")
print(toString(acc[1, 1]))


clean_accuracy = max(acc[1,1])
#8. compare results
result = d_accuracy < clean_accuracy  
print("result satisfied: "+result)

write(pip, output+"/pipelines.csv", format="csv")
write(hp, output+"/hyperparams.csv", format="csv")
write(acc, output+"/accuracies.csv", format="csv")
accuracies = cbind(as.matrix(d_accuracy), acc[1,1])
write(accuracies , output+"/BestAccuracy.csv", format="csv")
write(features, output+"/features.csv", format="csv")
write(result , $O)

accuracy = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) 
return (Matrix[Double] loss) {
  [prob, yhat, acc] = multiLogRegPredict(X=X, B=B, Y=y,  verbose=FALSE)
  loss = as.matrix(1 - (acc/100))
}



